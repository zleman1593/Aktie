use :node;

//File System
var fs = ::Meteor.npmRequire('fs');
//OS utilities
var os = ::Meteor.npmRequire('os');
//Temporary Arry of all transfered Chunks
var chunks = [];


var writeLocation = '../web.browser/app/';
var readLocation = writeLocation;
var TESTING_INDEX_NODES = ["http://IndexNode.meteor.com","http://localhost:5000"];
var ONE_MIB = 1048576; // // 1 MiB
var CHUNK_SIZE = ONE_MIB * 5;


::Meteor.startup(fn() {

    //Maybe alert an Index node that it is online?
    ::getOwnIPAndPort();
});


::Meteor.methods({

    registerFiletoShare: fn(fileName) {
         this.unblock;
         var error = ::registerFiletoShare(fileName);
         if error? {
        throw new ::Meteor.Error(500, 'Error 500: Not found', 'the file is not found');
      }

    },

    //Called when the peer node wants to get a file
    download: fn(file) {
        this.unblock;
        var fileName = file;
        //Connect to an Index Node
        var indexNodeIP = ::findIndexNode();
        var IndexNode = ::DDP.connect(indexNodeIP);


        IndexNode.call('findFile', {
            "fileName": fileName
        }, fn(error, result) {
            if error? {

            } else {
                console.log("Obtained File Location Information");
                ::initPeerFileTransfer(result, fileName);

            }
        });

    },

    //Called when another peer wants part of a file from this client
    getFileChunks: fn(requestedChunks) {
         this.unblock;
        var chunkNumber = requestedChunks.chunk;
        var fileName = ::requestedChunks.fileName;
        var data = ::getChunkOfFile(fileName, chunkNumber);
        return {
            "rawData": data,
            "chunkNumber": chunkNumber
        };
    }
});

/*Will identify the most optimal IndexNode to connenct to.*/
 fn findIndexNode() {
    return TESTING_INDEX_NODES[0];
 } 



 fn getOwnIPAndPort() {
    var interfaces = os.networkInterfaces();
    var addresses = [];
    for  k in interfaces {
        for  k2 in interfaces[k] {
            var address = interfaces[k][k2];
            if address.family == 'IPv4' && !address.internal {
                addresses.push(address.address);

            }
        }
    }

    console.log("\(addresses[0]):\(process.env.PORT)");
    return "\(addresses[0]):\(process.env.PORT)";

  } 


/*When a client node wants to indicate to the network that it is avalible to share a file*/
fn registerFiletoShare(fileName) {
    var IndexNode = ::DDP.connect(findIndexNode());
    var hostNameWithPort = getOwnIPAndPort();
    var filepath = '\(readLocation)\(fileName)';
    var numberOfParts = ::splitFileCount(filepath);
    if numberOfParts.error? { return numberOfParts.error;}

    IndexNode.call('registerFile', fileName, numberOfParts.result, hostNameWithPort, fn(error, result) {
        if (error) {
            console.log("Registration Failed");
        } else {
            console.log("Registered File with Index Server");

        }
    });
    return null;
}

/*Returns a specific chunk of the requested file*/
 fn getChunkOfFile(fileName, chunk) {
    console.log("Returning chunk File");
    var base64File  = ::fileSplit("\(readLocation)\(fileName)",chunk);
    if  base64File.result == -1{
     base64File = ::getWholeFile("\(readLocation)\(fileName)",chunk);
 }
      //  console.log(base64File);
    return {
        "base64File": base64File,
        "part": chunk
    };
}

/*Merges chunks of file once all chunks have been downloaded to local client node*/
 fn concatFile(chunkList) {

    //Make sure binary data string chunks are appeneded in the correct order
    chunkList.sort(fn(a, b) {
        if a.chunkNumber < b.chunkNumber {
            return -1;
        } else {
            return 1;
        }

    });
//console.log(chunkList);
//console.log(JSON.stringify(chunkList));

    var data = chunkList[0].rawData.base64File.result;

    for var i = 1; i < chunkList.length; i++ {
        data += chunkList[i].rawData.base64File.result;
    }
    return data;
}

/*Write the concatednated file to the local file system*/
 fn writeConcatedFile(base64String, fileName) {
    var decodedImage = new ::Buffer(base64String, 'base64');
    fs.writeFile(writeLocation + fileName, decodedImage, fn(err) {});

    ::resetForNextFileTransfer(fileName);

}

 fn resetForNextFileTransfer(fileName) {
    //Reset chunks buffer
    chunks = [];
    //Now that the client node hat the whole file, it should share it with other peers
    registerFiletoShare(fileName);
}

/*Get all chunks from avalible peers*/
 fn initPeerFileTransfer(chunkHolder, fileName) {
    console.log("Start Calling Peers for file transfer");
//Todo; Sort chunks by peer. Start transfers from that peer with one open connection. The start others
    for var chunk = 0; chunk < chunkHolder.chunks.length; chunk++ {

        var peer = ::DDP.connect(chunkHolder.chunks[chunk].chunk);
        peer.call('getFileChunks', {
            "fileName": fileName,
            "chunk": chunk
        }, fn(error, result) {
            if error? {
                console.log("ERROR for peer: \(chunk)");
            } else {
                console.log("Retrieved peer: \(chunk ) info");
                chunks.push(result);
                if chunks.length == chunkHolder.chunks.length {
                    var concatedFile = concatFile(chunks);
                    writeConcatedFile(concatedFile, fileName);
                }
            }
        });
    }

}

/*Calcuate hwo many parts a given file should be split into*/
 fn splitFileCount(filePath) {
    var fileName  = filePath;

   var parts =  ::Async.runSync(fn(done)  {

            fs.stat(filePath, fn (err, stats) {
                      if err? {
                        console.error(err);
                        return done(err,null);
                      }

                      if stats.isDirectory() {
                        console.error(fileName + ' is a directory, but must be a file');
                          return done(null,0);
                      }

                      if stats.size < CHUNK_SIZE {
                        console.log(fileName + ' is less than ' + CHUNK_SIZE / ONE_MIB + ' MiB, won\'t be split');
                        return done(null,1);
                      }

                      var parts = Math.ceil(stats.size / CHUNK_SIZE);
                      console.log("\(filePath) will be split into \(parts)");
                      return done(null,parts);
                });
    });
     //console.log(parts.result);
     return parts;
}


fn fileSplit(file,chunkNumber){
    var fileName  = file;
    var fileChunk =  ::Async.runSync(fn(done)  {
           fs.stat(file, fn (err, stats) {
                     if err? {
                       console.error(err);
                       return done(err,null);
                     }

                     if stats?.isDirectory() {
                       console.error(file + ' is a directory, but must be a file');
                         return done({"reason":file + ' is a directory, but must be a file'},null);
                     }

                     if stats.size < CHUNK_SIZE {
                       console.log(file + ' is less than ' + CHUNK_SIZE / ONE_MIB + ' MiB, won\'t be split');
                       return done(null,-1);
                     }

                    done(null,1);
               });
 });
    if fileChunk.result == 1 {

                        var readStream;
                       var data = '';
                       var start = CHUNK_SIZE * chunkNumber;
                       var end = start + CHUNK_SIZE - 1;
                     
                       readStream = fs.createReadStream(file, { flags: 'r', encoding: 'base64', start: start, end: end });

                       readStream.on('data', fn(chunk) {
                           data+=chunk;

                           });
                       fileChunk = ::Async.runSync(fn(done)  {
                      
                       readStream.on('end', fn() {

                           done(null,data);
                           });
                 
                  });
                           
                    }


        return fileChunk;
}


fn getWholeFile(fileName) {
    console.log("Returning Whole File As one Chunk");
    var encodedData = ::Async.runSync(fn (done) {
            fs.readFile(fileName, fn(err, original_data) {
             if !err? {
                      done(null,original_data.toString("base64"));
              } else {
                     console.log("error");
                    }
             });
    });

return encodedData;
}
