

//Load external libraries
use :node;

var randomAccessFile = ::Meteor.npmRequire('random-access-file');

//File System
var fs = ::Meteor.npmRequire('fs');
//OS utilities
var os = ::Meteor.npmRequire('os');
//Temporary Arry of all transfered Chunks
var chunks = [];
var missingChunks = [];
//Time given to allow for connection before verifying connection status
var SERVER_DELAY = 1500; //ms
var numberOfParts = 0;

//Folder to read and write fiels from
var writeLocation = '../web.browser/app/';//'/home/zleman/'; 
//var writeLocation = '../web.browser/app/';

var readLocation = writeLocation;
//Initial Index Nodes that this version of the software ships with
var currentIndexNodes = ["http://IndexNode0.meteor.com", "http://IndexNode.meteor.com","http://IndexNode2.meteor.com","http://IndexNode3.meteor.com"];
var ONE_MIB = 1048576; // 1 MiB
var CHUNK_SIZE = ONE_MIB * 10;

//Variable to keep track of Index Node that client is conencted to.
var IndexNode;
//Whether to write to disk once or during chunk download
var distributeIO = true;
//Is transfer of file complete?
var transferComplete = true;
//Info for file being written to disk
var openFileName = null;
var openFD = null;

//Run on client node start
::Meteor.startup(fn() {
    ::getOwnIPAndPort();
});

//Time download starts
var startTime;

//API for GUI to call methods on its server and for other client nodes to call methods on each other
::Meteor.methods({
    
        //Called in GUI to register a local file with an index node
        registerFiletoShare: fn(fileName) {
            this.unblock;
            var error = ::registerFiletoShare(fileName);
            if error? {
                throw new::Meteor.Error(500, 'Error 500: Not found', 'the file is not found');
            }
            
        },

        //For GUI to display local fiels to share
        getShareableFiles: fn() {
           this.unblock;
           var result = fs.readdirSync(readLocation);
           console.log(result);
           return result;
            
        },

        //For GUI
        getPercent: fn() {
            this.unblock;
            return (  chunks.length /  numberOfParts) * 100;
            
        },
            
        //Called in GUI when this client node wants to get a file
        download: fn(file) {
            this.unblock;
            var fileName = file;
            //Connect to an Index Node
            ::IndexNode = ::IndexNode if IndexNode?.status().connected else ::DDP.connect(::findIndexNode(fileName));
            
            //RPC (DDP) method call  to Index Node
            ::IndexNode.call('findFile', {
                "fileName": fileName
            }, fn(error, result) {
                if error? {
                        console.log(error.reason);
                        throw new ::Meteor.Error(240, "Error 320: Could Not find file", "A file by this name has not been registered.");
                } else {
                    console.log("Obtained File Location Information");
                    transferComplete = false;
                    startTime = new Date();
                    ::initPeerFileTransfer(result, fileName);
                }
            });
            
        },
            
        //Called when another peer wants part of a file from this client
        //Returns a chunk of the requested file
        getFileChunks: fn(requestedChunks) {
            this.unblock;
            var chunkNumber = requestedChunks.chunk;
            var fileName = ::requestedChunks.fileName;
            var data = ::getChunkOfFile(fileName, chunkNumber);
            return {
                "rawData": data,
                "chunkNumber": chunkNumber
            };
        }
});

//----------------------------------END API--------------------------


/*Will identify the correct IndexNode to connenct to given the file name.*/
fn findIndexNode(fileName) {
    return currentIndexNodes[::hash(fileName)];
}



/*When a client node wants to indicate to the network that it is avalible to share a file*/
fn registerFiletoShare(fileName) {
    var filepath = '\(readLocation)\(fileName)';
    numberOfParts = ::splitFileCount(filepath);

    if numberOfParts.error? {
        return numberOfParts.error;
    }

    ::IndexNode = ::IndexNode if (::IndexNode and ::IndexNode.status().connected) else ::DDP.connect(::findIndexNode(fileName));
    var hostNameWithPort = getOwnIPAndPort();
    
    //Tell index node to register the whole file for the first time
    ::IndexNode.call('registerFile', fileName, numberOfParts.result, hostNameWithPort, false, fn(error, result) {
        if error? {
            console.log("Registration Failed");
        } else {
            console.log("Registered File with Index Server");
            
        }
    });
}

/*When a client node wants to indicate to the network that it is avalible to share a file*/
fn registerFileChunkToShare(fileName,chunkNumber) {
    ::IndexNode = ::IndexNode if IndexNode?.status().connected else ::DDP.connect(::findIndexNode(fileName));
    var hostNameWithPort = getOwnIPAndPort();

    //Tell index node to register A chunk of file for the first time
    ::IndexNode.call('registerFileChunk', fileName, chunkNumber, hostNameWithPort, false, fn(error, result) {
        if (error) {
            console.log("Registration of Chunk Failed");
        } else {
            console.log("Registered File Chunk with Index Server");
            
        }
    });
}

/*Returns a specific chunk of the requested file*/
fn getChunkOfFile(fileName, chunk) {
    if  fileName == openFileName {
        var offset = CHUNK_SIZE * chunk;
        var length =  CHUNK_SIZE;
        var base64File = ::Async.runSync( fn(done) {
            openFD.read(offset,length , fn(err, buffer) {
                done(null,buffer);
            });
        });
        return {
            "base64File": base64File,
            "part": chunk
        };
        
    } else{
        console.log("Returning chunk File");

        var base64File = ::fileSplit("\(readLocation)\(fileName)", chunk);

        if base64File.result == -1 {
            base64File = ::getWholeFile("\(readLocation)\(fileName)", chunk);
        }
        
        return {
            "base64File": base64File,
            "part": chunk
        };
    }
}

/*Merges chunks of file once all chunks have been downloaded to local client node*/
fn concatFile(chunkList) {
    //Make sure binary data string chunks are appeneded in the correct order
    chunkList.sort(fn(a, b) {
        if a.chunkNumber < b.chunkNumber {
            return -1;
        } else {
            return 1;
        }
        
    });
    
    var data = chunkList[0].rawData.base64File.result;
    
    for var i = 1; i < chunkList.length; i++{
        data += chunkList[i].rawData.base64File.result;
    }
    return data;
}

/*Write the concat file to the local file system*/
fn writeConcatedFile(base64String, fileName) {
    ::Async.runSync( fn(done) {
        var decodedImage = new::Buffer(base64String, 'base64');
        fs.writeFile(writeLocation + fileName, decodedImage, fn(err) {done(null,null);});
    });
}

/*Write the file chunk to the local file system in the correct location*/
fn writeFileRandomly(base64String, fileName,chunkNumber) {
    var decodedImage = new::Buffer(base64String, 'base64');
    var offset = CHUNK_SIZE * chunkNumber;
    // an optional file size can be given as 2nd param to randomAccessFile
    var file = randomAccessFile(writeLocation + fileName);
    
    ::Async.runSync( fn(done) {
        file.write(offset, decodedImage, fn(err) {
            done(null,"closed");
        });
    });
    
    return file;
    
}
    //Reset server state for another download
fn resetForNextFileTransferIfFileWasConcatedInMemory(fileName) {
    //Reset chunks buffer
    chunks = [];
    missingChunks = [];
    //Now that the client node hat the whole file, it should share it with other peers
    registerFiletoShare(fileName);
    numberOfParts = 0;
}

    //Reset server state for another download
fn resetForNextFileTransferIfFileWasConcatedOnDisk() {
    //Reset chunks buffer
    chunks = [];
    missingChunks = [];
    openFileName = null;
    openFD = null;
    numberOfParts = 0;
}



/*Get all chunks from avalible peers*/
fn initPeerFileTransfer(chunkHolder, fileName) {

     console.log("Start Calling Peers for file transfer");

     numberOfParts = chunkHolder.chunks.length;

    //FutureTodo: Sort chunks by peer. Start transfers from that peer with one open connection. The start others

    //Loop through all chunks and connect to the peer need to obtain each chunk
    //Even though Node.js is run on a single thread these network requests all
    // go out within a few seconds of each other.
    //Teh do not block and wait for a response
    for var chunk = 0; chunk < chunkHolder.chunks.length; chunk++{
        var host = chunkHolder.chunks[chunk].chunk;
        ::Meteor.defer(fn() {
            ::getChunk(chunk, fileName, host,numberOfParts, true);
        });
    }

    //Collect all the missing parts

    //Only allows for one more attempt for obtaining a chunk if  it fails during the first attempt.
    // Need to make more robust with more retries
    //Run this every second after all initial chunk requests have gone out
    var timer = ::setInterval(::Meteor.bindEnvironment(fn() {
        var end = new Date();
        var diff = end - startTime;
        console.log(diff);
        console.log("Have all initial attemps to get chunks been made?");

        //If the number of successfully downloaded chunks + the number of replacement chunks to be downloaded 
        // equals the total number of chunks 
        if missingChunks.length + chunks.length == numberOfParts  {
            ::clearTimeout(::timer);
            //While the array that stores the chunks that failed is not empty. 
            //Attempt to get chunk from another peer
            while missingChunks.length != 0 {
                    var retry =  missingChunks.pop();
                    ::getChunk(retry.chunkNumber, fileName,retry.chunk, numberOfParts, false);
            }
            
        } else {
            //Else Initial attempts are  still occuring so wait for those to finish
            console.log("Not yet. Currently we have only tried to get " + (missingChunks.length + chunks.length) + "chunks.");
            //While timer was not executing the file was finished downloading. This will stop the timer
            if transferComplete {
                //stops timer
                ::clearTimeout(::timer);
            }
        }
    }),1000);
    
}


//This is the method initiates the network request for a chunk 
//and handles down peers
//It is given a file name,chunk number and peer (host) to which it will connect
//and grab the correct fiel chunk
fn getChunk(chunk, fileName,host,numberOfParts,firstTime) {
    if ::getOwnIPAndPort() == host {return;}//debugging
    
    var peer = ::DDP.connect(host);

    var status = ::Async.runSync(fn(done) {
        setTimeout(fn() {
            done(null, peer.status());
        }, SERVER_DELAY); //enough time to allow connection
    });
    
    //If connected to peer with chunk
    if status.result.connected {
        var hostHolder = host;

        console.log("Peer \(chunk) available!");
        //Call the method on the peer to return the correct chunk
        peer.call('getFileChunks', {
            "fileName": fileName,
            "chunk": chunk
        }, fn(error, result) {
            if error? {
                console.log("ERROR during connection to peer: \(chunk)");
                //needs more error handeling in future

            } else {
                console.log("Retrieved peer: \(chunk ) info");

                //Depending on if there shoudl be random disk writes or one disk write
                //either write file to disk and register chunk with index node
                //or store chunk in memory to be concatenated later
                if !distributeIO {
                    chunks.push(result);
                } else{
                    chunks.push(chunk);
                    openFD = writeFileRandomly(result.rawData.base64File.result, fileName,chunk);
                    openFileName = openFD.fileName;
                    //share the chunk
                    registerFileChunkToShare(fileName,chunk);
                }
                
                //If this was the last chunk to download
                if chunks.length == numberOfParts {

                        transferComplete = true;
                        var end = new Date();
                        var diff = end - startTime;
                        console.log(diff);

                    //Write fiel to disk and reset for another fiel transfer
                    if !distributeIO {
                        var concatedFile = concatFile(chunks);
                        writeConcatedFile(concatedFile, fileName);
                        ::resetForNextFileTransferIfFileWasConcatedInMemory(fileName);
                    } else{
                        openFD.close(fn() {console.log('file is closed');});
                        ::resetForNextFileTransferIfFileWasConcatedOnDisk();
                    }
                    
                }
            }
        });
    } else {
        //If peer is down---------------

        peer.disconnect();//Prevent reconnection attemps
        //Ask index server for new machien for chunk
        console.log("Could not connect to peer server for chunk \(chunk)");

        ::IndexNode = ::IndexNode if (::IndexNode and ::IndexNode.status().connected) else ::DDP.connect(::findIndexNode(fileName));

        console.log("Connection to IndexNode: " + IndexNode.status());
        //Ask Index node for replacement 
        ::IndexNode.call("getReplacementChunk", {
            "fileName": fileName,
            "chunkNumber": chunk,
            "badMachine": host
        }, fn(error, result) {
            if error? {
                console.log("Error: Could not Obtain Replacement Chunk location From Index");
            } else {
                console.log("Obtained Replacement Chunk File Location Information: \(JSON.stringify(result.chunk))");
                if firstTime {
                    ::missingChunks.push(result.chunk);
                }
                
            }
        });
    }
    
}

/*Calculate hwo many parts a given file should be split into*/
fn splitFileCount(filePath) {
    var fileName = filePath;
    
    var parts = ::Async.runSync(fn(done) {
        
        fs.stat(filePath, fn(err, stats) {
            if err? {
                console.error(err);
                return done(err, null);
            }
            
            if stats.isDirectory() {
                console.error(fileName + ' is a directory, but must be a file');
                return done(null, 0);
            }
            
            if stats.size < CHUNK_SIZE {
                console.log(fileName + ' is less than ' + CHUNK_SIZE / ONE_MIB + ' MiB, won\'t be split');
                return done(null, 1);
            }
            
            var parts = Math.ceil(stats.size / CHUNK_SIZE);
            console.log("\(filePath) will be split into \(parts)");
            return done(null, parts);
        });
    });
    //console.log(parts.result);
    return parts;
}

//Returns the data associated with a chunk that is stored on the local disk
fn fileSplit(file, chunkNumber) {
    var fileName = file;
    var fileChunk = ::Async.runSync(fn(done) {
        fs.stat(file, fn(err, stats) {
            if err? {
                console.error(err);
                return done(err, null);
            }
            
            if stats ? .isDirectory() {
                console.error(file + ' is a directory, but must be a file');
                return done({
                    "reason": file + ' is a directory, but must be a file'
                }, null);
            }
            
            if stats.size < CHUNK_SIZE {
                console.log(file + ' is less than ' + CHUNK_SIZE / ONE_MIB + ' MiB, won\'t be split');
                return done(null, -1);
            }
            
            done(null, 1);
        });
    });
    
    if fileChunk.result == 1 {
        var data = '';
        var readStream;
        
        var start = CHUNK_SIZE * chunkNumber;
        var end = start + CHUNK_SIZE - 1;
        
        readStream = fs.createReadStream(file, {
        flags: 'r',
        encoding: 'base64',
        start: start,
        end: end
        });
        
        readStream.on('data', fn(chunk) {
            data += chunk;
        });
        fileChunk = ::Async.runSync(fn(done) {
            
            readStream.on('end', fn() {
                
                done(null, data);
            });
            
        });
        
    }
    
    
    return fileChunk;
}

//For files under chunk size just read and return the whole file
fn getWholeFile(fileName) {
    console.log("Returning Whole File As one Chunk");
    var encodedData = ::Async.runSync(fn(done) {
        fs.readFile(fileName, fn(err, original_data) {
            if !err? {
                done(null, original_data.toString("base64"));
            } else {
                console.log("error");
            }
        });
    });
    
    return encodedData;
}

//Hash of file name
fn hash(fileName){
    var sum = 0;
    for var i = 0; i < fileName.length; i++ {
        sum += fileName.charCodeAt(i);
    }
    
    var bucket = (sum % 4 );
    
    return bucket;
}

//Percent of file downloaded
fn getPercent() {
    this.unblock;
    return (  chunks.length /  numberOfParts) * 100;
    
}
